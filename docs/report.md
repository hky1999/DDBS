# DDBS Project

郝子胥 2023310803
田凯夫 2023310805

## 构建和运行项目

hadoop 搭建参考仓库 https://github.com/big-data-europe/docker-hadoop 。

用 docker-compose 配置 hadoop ，读写文件需要暴露 datanode 的端口，需要修改 /etc/hosts 并将其映射至 127.0.0.1 。

在项目目录下执行 `./prepare.sh` 安装依赖工具。

执行 `./run_docker.sh` 运行 docker 容器（端口默认给定，可能出现冲突）。

执行 `python -m server.server --init` 将预先生成好的数据分块并导入到 DBMS 和 HDFS 中。

执行 `python -s tests/test_server.py` 运行测试。

## 项目架构

![](overview.svg)

- Server 对数据进行划分和布局，接收用户请求并制定查询方案
- Hadoop FS 可以对文章内容等大文件进行保存，减少本地的存储负担
- MongoDB 是 NoSQL 数据库，使用文档类型保存数据，具备良好的扩展性和丰富的查询方法（MQL）
- Redis 内存数据库用于对 MongoDB 中的数据进行缓存，加快查询的响应，减少对存储设备频繁的访问

## 功能简介

- 查询、插入、更新用户数据
- 查询某用户阅读历史
- 查询某文章详细内容，包括文本、图片和视频
- 获取某天、某周、某月内最受欢迎的文章信息
- 可实时监控数据库的状态

## 功能设计

### 数据库初始化

#### 结构化数据表的建立

能够直接从数据中构建的表（按MongoDB的称呼为集合）包括user、article和read，剩余的be_read表和popular_rank表需要从前3个表构造，它们在逻辑上是materialized views。

be_read表中最重要的索引字段为`aid`和`timestamp`，逻辑上动态的be_read查询应当指定目标文章ID和查询的时间戳区间，通过聚合在该时间范围内涉及文章`aid`的read表记录得到查询结果。虽然理论上给定任意的文章ID和时间区间都会查询到对应be-read结果，但文章ID和时间区间的组合空间过大，我们无法为每个组合建立对应的be-read表项。考虑到popular_rank文章信息查询的最小时间粒度为天，我们只需以天为`timestamp`粒度创建记录，并且区间查询可以由两次前缀和的结果做差得到；因此我们对read表项涉及时间范围中的每个整数天时间戳和所有文章ID建立be-read记录，聚合指定文章在该时间戳之前所有的阅读记录。

popular_rank表主要通过`timestamp`（和`temporalGranularity`）字段查询。它对应的动态查询也需指定时间范围，在be_read查询结果的基础上排序选择出具有最高阅读量（或者其它体现受欢迎程度的统计指标）的文章ID列表。在实际构建popular_rank表时，对于每个整数天时间戳可以进行4次对be-read表的时间前缀和查询，然后做差得到3个时间粒度的文章阅读量等信息，最终选择出文章列表构造一条记录。

#### 非结构化数据

非结构化数据主要为“大型”的文本、图片和视频文件，直接将它们上传到Hadoop HDFS即可。

### 支持缓存的查询

我们选择对单表查询添加缓存，即查询条件到查询结果的映射，采用Redis中的哈希表实现。具体地，我们设计了两类缓存，一类是对象ID到对象记录的细粒度精确缓存，另一类是通用的查询条件到查询结果的缓存。第一类缓存受数据更新的影响相对较小，更新无关记录或插入新记录不会导致单个缓存项失效；第二类缓存受数据更新影响较大，任何记录插入或更新都会导致该表上的所有缓存项失效。

此外，数据查询需要考虑到数据水平分片的影响。系统中的Redis实例与MongoDB实例绑定，缓存层对server组件（API网关）透明（缓存层不是中心化的）。我们采用的通用方法是中心化网关会向所有相关的（带缓存层的）数据库实例发送查询请求，然后合并多个返回的查询结果。

### 数据更新

考虑以下的数据更新操作：

- 插入新的用户/文章记录（插入user, article表）
- 修改用户/文章记录的某些字段（修改user, article表）
- 追加新的文章阅读记录（插入read表）

插入新的用户/文章记录时，在请求MongoDB之外需要修改Redis缓存。目标表上的精确对象缓存项不受影响，其它的通用查询缓存会被丢弃。修改现有的用户/文章记录字段时同理。在实现上我们暂不支持修改用于水平分片的字段，此类修改会影响到多个表。

根据需求，我们只考虑文章阅读记录的追加，不涉及对现有阅读记录的修改。对read表和相应缓存的修改与user和article表类似，剩下的问题是对be_read表和popular_rank表的更新。我们认为它们无需在每次向read表插入新记录时更新，每隔一天计算并插入新产生的be_read和popular_rank记录即可。

### 状态监控

对MongoDB状态的监控借助于MongoDB Compass实现，Hadoop HDFS也有相应的监控工具。我们还设计了API接口返回MongoDB和Redis缓存的基本信息，包括各个表（集合）名、表大小、缓存表名和各表缓存项数量。

## 接口说明

### 内部通用接口

- `query_single_table_cached(handles, table_name, condition, id_key)`

通用单表查询接口，默认启用缓存。返回全局视图下对指定数据表按给定查询条件执行查询的结果，来自多个数据库分片的结果将被合并。

|参数名|类型|描述|
|-|-|-|
|handles|dict|固定的下游组件接口集合|
|table_name|str|待查询的表（集合）名|
|condition|Union[dict, None]|查询条件，遵循MQL查询格式|
|id_key|Union[str, None]|数据表的ID字段名称，用于合并来自多个数据库分片的结果|


- `insert_single_item(handles, table_name, item, id_key)`

单表插入接口，用于向单个数据表插入单个记录对象，考虑了分片规则。

|参数名|类型|描述|
|-|-|-|
|handles|dict|固定的下游组件接口集合|
|table_name|str|待插入的表（集合）名|
|item|dict|待插入的记录（文档）对象|
|id_key|str|待插入对象的ID字段名称，用于判重、缓存管理等|

- `update_single_item(handles, table_name, item, id_key)`

单表更新接口，用于更新单个数据表中的单个记录对象，考虑了分片规则。

|参数名|类型|描述|
|-|-|-|
|handles|dict|固定的下游组件接口集合|
|table_name|str|待更新的表（集合）名|
|item|dict|新的记录（文档）对象|
|id_key|str|新对象的ID字段名称，用于确定对象、缓存管理等|


### HTTP接口

- URL `/users`，方法 GET

获取所有的用户信息，返回JSON格式的全部用户记录。

- URL `/user/<uid>`，方法 GET/POST

GET方法获取具有给定uid的用户信息，POST方法依照给定uid对应的用户记录是否存在执行插入或更新动作（待插入/更新的用户对象解析自请求体）。

- URL `/articles`，方法 GET

获取所有的文章记录，不包括附加的文本、图片、视频等详细信息。

- URL `/article/<aid>`，方法 GET/POST

GET方法获取指定的文章信息，POST方法依照给定aid对应的文章记录是否存在执行插入或更新动作。

- URL `/user_read/<uid>`，方法 GET

获取具有给定uid的用户的阅读历史，包括每个阅读记录的ID和被阅读的文章信息。

- URL `/popular/<timestamp>`，方法 GET

获取给定时间戳对应的前一天、一周和一个月内最受欢迎的文章信息，包括每篇文章的文本、图片、视频附件。

- URL `/status`，方法 GET

获取当前时刻数据库和缓存的状态，包括各个分片的数据表名、各表大小、缓存表名、缓存大小。

- URL `/flush_cache`，方法 POST

清空Redis中的全部查询缓存。

<!--

## 实现细节

### 数据库初始化

我们注意到`xxx.dat`中每行数据（文档）的所有字段类型均为字符串，因此在建表过程中额外将后续可能参与查询条件的字段转化为了整数（包括`aid`、`uid`及逻辑上是数值的字段），并且在`uid`、`aid`、`timestamp`等字段上建立了索引。

-->

## 分工

- 郝子胥：系统设计、代码编写
- 田凯夫：系统搭建、前端测试
